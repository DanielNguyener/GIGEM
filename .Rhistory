# requires two quantitative variables (x explanatory) (y dependent)
# correlation coefficient
data("iris")
cor(iris$Sepal.Length, iris$Sepal.Width)
# [1] -0.1175698
plot(iris$Sepal.Length, iris$Sepal.Width)
abline(lm(iris$Sepal.Length, iris$Sepal.Width), col = "red")
abline(lm(iris$Sepal.Length~iris$Sepal.Width), col = "red")
?abline
reg <- lm(iris$Sepal.Length~iris$Sepal.Width)
reg
abline(reg), col = "red")
abline(reg, col = "red")
reg <- lm(iris$Sepal.Length,iris$Sepal.Width)
data("diabetes")
df <- read.csv("https://raw.githubusercontent.com/Sutanoy/Public-Regression-Datasets/main/diabetes.csv",
header = TRUE)
# [1] -0.1175698
plot(iris$Sepal.Length,iris$Sepal.Width)
abline(reg, col = "red")
abline(reg, col = "red")
abline(reg = reg, col = "red")
abline(reg = lm(iris$Sepal.Length~iris$Sepal.Width), col = "red")
# [1] -0.1175698
plot(iris$Sepal.Length,iris$Sepal.Width)
abline(reg = lm(iris$Sepal.Length~iris$Sepal.Width), col = "red")
# [1] -0.1175698
plot(iris$Sepal.Length,iris$Sepal.Width)
abline(reg = lm(iris$Sepal.Length~iris$Sepal.Width), col = "red")
plot(df$glutest,df$insulin)
abline(reg=lm(df$glutest~df$insulin), col = "red")
abline(reg=lm(df$glutest~df$insulin))
abline(reg=lm(df$glutest~df$insulin, data = df))
plot(df$glutest,df$insulin)
abline(reg=lm(df$glutest~df$insulin, data = df))
abline(reg=lm(glutest~insulin, data = df))
plot(df$glutest,df$insulin)
abline(reg=lm(glutest~insulin, data = df))
abline(reg = reg_model, col = "blue")
plot(df$glutest,df$insulin)
reg_model <- lm(insluin ~ glutest, data=df)
abline(reg = reg_model, col = "blue")
summary(reg_model)
reg_model <- lm(insluin ~ glutest, data=df)
summary(reg_model)
reg_model <- lm(insluin ~ glutest, data=df)
reg_model <- lm(insulin ~ glutest, data=df)
summary(reg_model)
abline(reg = reg_model, col = "blue")
data("PlantGrowth")
ctrl = PlantGrowth$weight[PlantGrowth$group =="ctrl"]
trt2 = PlantGrowth$weight[PlantGrowth$group =="trt2"]
t.test(ctrl, trt2)
ctrl
trt2
older=c(820.6904 , 665.7364,  987.6499 , 741.2296 , 596.4297 , 719.0579 , 646.1210 , 636.4951 , 804.1621 , 790.7087,926.6503,638.1746,  649.0670,  862.6648 , 709.4548,  846.9925,  743.8323 , 594.9721 , 737.0955 , 743.0698,910.336,636.0315, 1082.3368 , 728.6455  ,749.9248,  739.6448,  728.3797,  820.7704)
younger=c(772.5276,772.6000,622.5930,735.5894,805.3839,779.2155 ,710.4776, 853.9633, 806.6726, 688.1146, 907.7591,702.8668, 761.0117, 945.8701 ,755.3278 ,796.3251)
?t.test()
# null: less
t.test(older, younger, alternative ="less")
older=c(820.6904 , 665.7364,  987.6499 , 741.2296 , 596.4297 , 719.0579 , 646.1210 , 636.4951 , 804.1621 , 790.7087,926.6503,638.1746,  649.0670,  862.6648 , 709.4548,  846.9925,  743.8323 , 594.9721 , 737.0955 , 743.0698,910.336,636.0315, 1082.3368 , 728.6455  ,749.9248,  739.6448,  728.3797,  820.7704)
Indoor=c(.07,.08,.09,.12,.12,.12,.13,.14,.15,.15,.17,.17,.18,.18,.18,.18,.19,.20,.22,.22,.23,.23,.25,.26,.28,. 28,.29,.34,.39,.40,.45,.54,.62) Outdoor=c(.29,.68,.47,.54,.97,.35,.49,.84,.86,.28,.32,.32,1.55,.66,.29,.21,1.02,1.59,.90,.52,.12,.54,.88,.49 ,1.24,.48,.27,.37,1.26,.70,.76,.99,.36)
Indoor=c(.07,.08,.09,.12,.12,.12,.13,.14,.15,.15,.17,.17,.18,.18,.18,.18,.19,.20,.22,.22,.23,.23,.25,.26,.28,. 28,.29,.34,.39,.40,.45,.54,.62)
Outdoor=c(.29,.68,.47,.54,.97,.35,.49,.84,.86,.28,.32,.32,1.55,.66,.29,.21,1.02,1.59,.90,.52,.12,.54,.88,.49 ,1.24,.48,.27,.37,1.26,.70,.76,.99,.36)
Indoor=c(.07,.08,.09,.12,.12,.12,.13,.14,.15,.15,.17,.17,.18,.18,.18,.18,.19,.20,.22,.22,.23,.23,.25,.26,.28,. 28,.29,.34,.39,.40,.45,.54,.62)
Indoor=c(.07,.08,.09,.12,.12,.12,.13,.14,.15,.15,.17,.17,.18,.18,.18,.18,.19,.20,.22,.22,.23,.23,.25,.26,.28,. 28,.29,.34,.39,.40,.45,.54,.62)
Indoor=c(.07,.08,.09,.12,.12,.12,.13,.14,.15,.15,.17,.17,.18,.18,.18,.18,.19,.20,.22,.22,.23,.23,.25,.26,.28,. 28,.29,.34,.39,.40,.45,.54,.62)
Outdoor=c(.29,.68,.47,.54,.97,.35,.49,.84,.86,.28,.32,.32,1.55,.66,.29,.21,1.02,1.59,.90,.52,.12,.54,.88,.49 ,1.24,.48,.27,.37,1.26,.70,.76,.99,.36)
Indoor=c(.07,.08,.09,.12,.12,.12,.13,.14,.15,.15,.17,.17,.18,.18,.18,.18,.19,.20,.22,.22,.23,.23,.25,.26,.28,. 28,.29,.34,.39,.40,.45,.54,)
Indoor=c(.07,.08,.09,.12,.12,.12,.13,.14,.15,.15,.17,.17,.18,.18,.18,.18,.19,.20,.22,.22,.23,.23,.25,.26,.28,.28,.29,.34,.39)
Indoor=c(.07,.08,.09,.12,.12,.12,.13,.14,.15,.15,.17,.17,.18,.18,.18,.18,.19,.20,.22,.22,.23,.23,.25,.26,.28,.28,.29,.34,.39,.40,.45,.54,.62)
Outdoor=c(.29,.68,.47,.54,.97,.35,.49,.84,.86,.28,.32,.32,1.55,.66,.29,.21,1.02,1.59,.90,.52,.12,.54,.88,.49,1.24,.48,.27,.37,1.26,.70,.76,.99,.36)
t.test(Outdoor, Indoor, paired=TRUE, alternative="two.sided")
older=c(820.6904 , 665.7364,  987.6499 , 741.2296 , 596.4297 , 719.0579 , 646.1210 , 636.4951 , 804.1621 , 790.7087,926.6503,638.1746,  649.0670,  862.6648 , 709.4548,  846.9925,  743.8323 , 594.9721 , 737.0955 , 743.0698,910.336,636.0315, 1082.3368 , 728.6455  ,749.9248,  739.6448,  728.3797,  820.7704)
younger=c(772.5276,772.6000,622.5930,735.5894,805.3839,779.2155 ,710.4776, 853.9633, 806.6726, 688.1146, 907.7591,702.8668, 761.0117, 945.8701 ,755.3278 ,796.3251)
# null: less
t.test(older, younger, alternative ="less")
# null: less
t.test(older, younger, alternative ="greater")
mean(older)
mean(younger)
mean(older) > mean(younger)
# Kate's Exam
library(HardyWeinberg)
data("Mourant")
data
view(Mourant)
D="Mourant"[197,]
# Kate's Exam
library(HardyWeinberg)
data("Mourant")
D="Mourant"[197,]
D=Mourant[197,]
View(D)
load("C:/Users/danie/Desktop/Files/STAT 312/Final/New Material/ChargaffTable.RData")
load("C:/Users/danie/Desktop/Files/STAT 312/Final/New Material/ChargaffTable.RData")
nMM = Mourant$MM[197]
nMN = Mourant$MN[197]
nNN = Mourant$NN[197]
phat = af(c(nMM, nMN, nNN))
phat
?af()
1 - phat
nMM = Mourant$MM[216]
nMN = Mourant$MN[216]
nNN = Mourant$NN[216]
phat = af(c(nMM, nMN, nNN))
phat
nMM = Mourant$MM[197]
nMN = Mourant$MN[197]
nNN = Mourant$NN[197]
phat = af(c(nMM, nMN, nNN))
phat
1 - phat
data <- cars
View(data)
# find the average of the distances traveled with speed >= 19mph.
dats_speeds <- data$speed[data$speed >= 19]
datas_speeds
dats_speeds
# find the average of the distances traveled with speed >= 19mph.
dats_speeds <- data$speed[data$speed >= 19,]
# find the average of the distances traveled with speed >= 19mph.
dats_speeds <- data[data$speed >= 19]
# find the average of the distances traveled with speed >= 19mph.
dats_speeds <- data[data$speed >= 19,]
dats_speeds
dats_speeds$dist
average_dist = mean(dats_speeds$dist)
average_dist
?apply()
head(Mourant)
library(vegan)
data(dune)
View(dune)
dist.animals = dist(animals, diag=TRUE, method="eucledian")
dist.animals = dist(animals, diag=TRUE, method="euclidean")
dist.animals = dist(dune, diag=TRUE, method="euclidean")
dist.animals = dist(t(dune), diag=TRUE, method="euclidean")
View(dune)
t(dune)
a=hclust(dist.animals, method="single")
plot(a)
a
a$height
a$merge
?hclust()
####
Diagnosis.breastcancer <- read.csv("https://raw.githubusercontent.com/Sutanoy/Public-Regression-Datasets/main/bdiag.csv",sep=",",head=TRUE)
View(a)
View(Diagnosis.breastcancer)
test <- Diagnosis.breastcancer[c(23,6,12)]
test
?prcomp()
clust = kmeans(bdiag_newm, centers=2)
bdiag_new = Diagnosis.breastcancer[c(23,6,12)]
clust = kmeans(bdiag_newm, centers=2)
clust
clust = kmeans(bdiag_new, centers=2)
clust
table(out$cluster)
table(out$cluster)
table(clust$cluster)
0.8^2
0.64 * 1000
###
pHW = c(BB = 0.8^2, BA = 2*0.8*0.2, AA = 0.2^2)
0.2^2
0.04 * 1000
2*0.8*0.2*1000
320 + 640 + 40
# Kate's Exam
library(HardyWeinberg)
data("Mourant")
D=Mourant[195,]
nMM = Mourant$MM[195]
nMN = Mourant$MN[195]
nNN = Mourant$NN[195]
phat = af(c(nMM, nMN, nNN))
phat
1 - phat
older=c(820.6904 , 665.7364,  987.6499 , 741.2296 , 596.4297 , 719.0579 , 646.1210 , 636.4951 , 804.1621 , 790.7087,926.6503,638.1746,  649.0670,  862.6648 , 709.4548,  846.9925,  743.8323 , 594.9721 , 737.0955 , 743.0698,910.336,636.0315, 1082.3368 , 728.6455  ,749.9248,  739.6448,  728.3797,  820.7704)
younger=c(772.5276,772.6000,622.5930,735.5894,805.3839,779.2155 ,710.4776, 853.9633, 806.6726, 688.1146, 907.7591,702.8668, 761.0117, 945.8701 ,755.3278 ,796.3251)
t.test(older, younger, paired= FALSE, alternative= "less")
data <- cars
# find the average of the distances traveled with speed >= 19mph.
dats_speeds <- data[data$speed >= 19,]
average_dist = mean(dats_speeds$dist)
average_dist
library(vegan)
data(dune)
dist.animals = dist(t(dune), diag=TRUE, method="euclidean")
a=hclust(dist.animals, method="single")
plot(a)
a$height
data("PlantGrowth")
ctrl = PlantGrowth$weight[PlantGrowth$group =="ctrl"]
trt2 = PlantGrowth$weight[PlantGrowth$group =="trt2"]
t.test(ctrl, trt2)
t.test()
?t.test()
####
urlRemote  <- "https://raw.githubusercontent.com/"
pathGithub <- "Sutanoy/Public-Regression-Datasets/main/"
fileName   <- "bdiag.csv"
df_brca=read.csv(paste0(urlRemote, pathGithub, fileName) ,sep=",",header = TRUE)
head(df_brca)
#recoding the response variable to 0/1.
df_brca$diagnosis[df_brca$diagnosis=="M"]=1
df_brca$diagnosis[df_brca$diagnosis=="B"]=0
df_brca$diagnosis=as.numeric(df_brca$diagnosis)
fit <- lm(symmetry_mean~symmetry_worst, data = df_brca)
?lm()
fit
?glm()
tumor <- read.csv("https://raw.githubusercontent.com/Sutanoy/Public-Regression-Datasets/main/bdiag.csv", sep=",",
header = TRUE)
set.seed(312)
train_obs_rows = sample(1:nrow(tumor), size = 400) # the first 400 individuals (chosen randomly)
df_train= tumor[train_obs_rows,] #dataframe made up of the samples that trains_obs chose
df_test= tumor[- train_obs_rows,] #dataframe made up of the sampels that trains_obs didn't choose.
#fittng on the training samples
fit = glm(diagnosis ~ radius_mean + texture_mean, data=df_train, family = "binomial")
# then use the fit based on training, to test df_test
predicted = predict(fit, df_test, type="response")
# then see how much of df_test was predicted correctly.
y_hat=ifelse(predicted>0.5, 1,0) # recode to binary if greater than 50% for prediction
y_true = df_test$diagnosis
#fittng on the training samples
fit = glm(diagnosis ~ radius_mean + texture_mean, data=df_train)
# then use the fit based on training, to test df_test
predicted = predict(fit, df_test, type="response")
# then see how much of df_test was predicted correctly.
y_hat=ifelse(predicted>0.5, 1,0) # recode to binary if greater than 50% for prediction
y_true = df_test$diagnosis
tumor <- read.csv("https://raw.githubusercontent.com/Sutanoy/Public-Regression-Datasets/main/bdiag.csv", sep=",",
header = TRUE)
set.seed(312)
train_obs_rows = sample(1:nrow(tumor), size = 400) # the first 400 individuals (chosen randomly)
df_train= tumor[train_obs_rows,] #dataframe made up of the samples that trains_obs chose
df_test= tumor[- train_obs_rows,] #dataframe made up of the sampels that trains_obs didn't choose.
#fittng on the training samples
fit = glm(diagnosis ~ radius_mean + texture_mean, data=df_train)
# then use the fit based on training, to test df_test
predicted = predict(fit, df_test, type="response")
#fittng on the training samples
fit = glm(diagnosis ~ radius_mean + texture_mean, data=df_train, family)
#fittng on the training samples
fit = glm(diagnosis ~ radius_mean + texture_mean, data=df_train, family = "binomial")
tumor <- read.csv("https://raw.githubusercontent.com/Sutanoy/Public-Regression-Datasets/main/bdiag.csv", sep=",",
header = TRUE)
set.seed(312)
train_obs_rows = sample(1:nrow(tumor), size = 400) # the first 400 individuals (chosen randomly)
df_train= tumor[train_obs_rows,] #dataframe made up of the samples that trains_obs chose
df_test= tumor[- train_obs_rows,] #dataframe made up of the sampels that trains_obs didn't choose.
#fittng on the training samples
fit = glm(diagnosis ~ radius_mean + texture_mean, data=df_train, family = "binomial")
#example 2)
tumor <- read.csv("https://raw.githubusercontent.com/Sutanoy/Public-Regression-Datasets/main/bdiag.csv", sep=",",
header = TRUE)
set.seed(312)
train_obs_rows = sample(1:nrow(tumor), size = 400) # the first 400 individuals (chosen randomly)
df_train= tumor[train_obs_rows,] #dataframe made up of the samples that trains_obs chose
df_test= tumor[- train_obs_rows,] #dataframe made up of the sampels that trains_obs didn't choose.
#fittng on the training samples
fit = glm(diagnosis ~ radius_mean + texture_mean, data=df_train, family = "binomial")
# then use the fit based on training, to test df_test
predicted = predict(fit, df_test, type)
#fittng on the training samples
fit = glm(diagnosis ~ radius_mean + texture_mean, data=df_train, family = "binomial")
#cross-validation checks whether model is a good fit.
dim(tumor)
train_obs_rows = sample(1:nrow(tumor), size = 400) # the first 400 individuals (chosen randomly)
df_train= tumor[train_obs_rows,] #dataframe made up of the samples that trains_obs chose
df_test= tumor[- train_obs_rows,] #dataframe made up of the sampels that trains_obs didn't choose.
#fittng on the training samples
fit = glm(diagnosis ~ radius_mean + texture_mean, data=df_train, family = "binomial")
#example 2)
tumor <- read.csv("https://raw.githubusercontent.com/Sutanoy/Public-Regression-Datasets/main/bdiag.csv", sep=",",
header = TRUE)
set.seed(312)
train_obs_rows = sample(1:nrow(tumor), size = 400) # the first 400 individuals (chosen randomly)
df_train= tumor[train_obs_rows,] #dataframe made up of the samples that trains_obs chose
df_test= tumor[- train_obs_rows,] #dataframe made up of the sampels that trains_obs didn't choose.
#fittng on the training samples
fit = glm(diagnosis ~ radius_mean + texture_mean, data=df_train, family = "binomial")
#569 patients
#diagnosis = M/B (malignant or benign), recode response variable to -0/1
tumor$diagnosis[tumor$diagnosis == "M"] = 1
tumor$diagnosis[tumor$diagnosis == "B"] = 0
tumor$diagnosis=as.numeric(tumor$diagnosis) #Tell R to interpret these 0 and 1 as numbers and not characters.
set.seed(312)
train_obs_rows = sample(1:nrow(tumor), size = 400) # the first 400 individuals (chosen randomly)
df_train= tumor[train_obs_rows,] #dataframe made up of the samples that trains_obs chose
df_test= tumor[- train_obs_rows,] #dataframe made up of the sampels that trains_obs didn't choose.
#fittng on the training samples
fit = glm(diagnosis ~ radius_mean + texture_mean, data=df_train, family = "binomial")
# then use the fit based on training, to test df_test
predicted = predict(fit, df_test, type)
# then use the fit based on training, to test df_test
predicted = predict(fit, df_test)
# then see how much of df_test was predicted correctly.
y_hat=ifelse(predicted>0.5, 1,0) # recode to binary if greater than 50% for prediction
y_true = df_test$diagnosis #recode to binary (the actual correct num of B/M)
table(y_true, y_hat) #compare actual to prediction
list <- 3,5,6,7,9
list <- c(3,5,6,7,9)
std(list)
?std
sd(list)
qnorm(.065,47.88,3.09)
## Develop the Normal density and provide probabilities within limits
mean=101.8
sd=3.76
xmin=0
xmax=100
cc <- curve(dnorm(x,mean=mean,sd=sd), from = min(mean-4*sd), to =
max(mean+4*sd), main="Normal density at various levels of x",xlab = "x",
ylab = "p(x)")
polygon(c(xmin, cc$x[cc$x >= xmin & cc$x <= xmax], xmax), c(0,
cc$y[cc$x >= xmin & cc$x <= xmax], 0), col = "red")
p_x=pnorm(xmax,mean,sd)-pnorm(xmin,mean,sd)
p_x
## Develop the Normal density and provide probabilities within limits
mean=101.8
sd=0.69881
xmin=0
xmax=100
cc <- curve(dnorm(x,mean=mean,sd=sd), from = min(mean-4*sd), to =
max(mean+4*sd), main="Normal density at various levels of x",xlab = "x",
ylab = "p(x)")
polygon(c(xmin, cc$x[cc$x >= xmin & cc$x <= xmax], xmax), c(0,
cc$y[cc$x >= xmin & cc$x <= xmax], 0), col = "red")
p_x=pnorm(xmax,mean,sd)-pnorm(xmin,mean,sd)
p_x
## Develop the Normal density and provide probabilities within limits
mean=101.8
sd=0.77386
xmin=0
xmax=100
cc <- curve(dnorm(x,mean=mean,sd=sd), from = min(mean-4*sd), to =
max(mean+4*sd), main="Normal density at various levels of x",xlab = "x",
ylab = "p(x)")
polygon(c(xmin, cc$x[cc$x >= xmin & cc$x <= xmax], xmax), c(0,
cc$y[cc$x >= xmin & cc$x <= xmax], 0), col = "red")
p_x=pnorm(xmax,mean,sd)-pnorm(xmin,mean,sd)
p_x
##  Develop the Gamma density and provide probabilities within limits
##
xmin=0
xmax=1
alpha=30
beta=0.0333
cc <- curve(dgamma(x,alpha,scale=beta), from = 0, to = max(alpha*beta*4), main="Gamma density at various levels of x",xlab = "x", ylab = "p(x)")
polygon(c(xmin, cc$x[cc$x >= xmin & cc$x <= xmax], xmax), c(0, cc$y[cc$x >= xmin & cc$x <= xmax], 0), col = "red")
p_x=pgamma(xmax,alpha,scale=beta)-pgamma(xmin,alpha,scale=beta)
p_x
##  Simulation of mean and variance   Estimates!!
x=rgamma(1000000,alpha,scale=beta)
mean(x)
var(x)
##  Develop the Gamma density and provide probabilities within limits
##
xmin=0
xmax=1
alpha=3
beta=1/3
cc <- curve(dgamma(x,alpha,scale=beta), from = 0, to = max(alpha*beta*4), main="Gamma density at various levels of x",xlab = "x", ylab = "p(x)")
polygon(c(xmin, cc$x[cc$x >= xmin & cc$x <= xmax], xmax), c(0, cc$y[cc$x >= xmin & cc$x <= xmax], 0), col = "red")
p_x=pgamma(xmax,alpha,scale=beta)-pgamma(xmin,alpha,scale=beta)
p_x
xmax=1
alpha=3
beta=0.33
cc <- curve(dgamma(x,alpha,scale=beta), from = 0, to = max(alpha*beta*4), main="Gamma density at various levels of x",xlab = "x", ylab = "p(x)")
polygon(c(xmin, cc$x[cc$x >= xmin & cc$x <= xmax], xmax), c(0, cc$y[cc$x >= xmin & cc$x <= xmax], 0), col = "red")
p_x=pgamma(xmax,alpha,scale=beta)-pgamma(xmin,alpha,scale=beta)
p_x
##  Develop the Gamma density and provide probabilities within limits
##
xmin=0
xmax=1
alpha=3
beta=(1/3)
cc <- curve(dgamma(x,alpha,scale=beta), from = 0, to = max(alpha*beta*4), main="Gamma density at various levels of x",xlab = "x", ylab = "p(x)")
polygon(c(xmin, cc$x[cc$x >= xmin & cc$x <= xmax], xmax), c(0, cc$y[cc$x >= xmin & cc$x <= xmax], 0), col = "red")
p_x=pgamma(xmax,alpha,scale=beta)-pgamma(xmin,alpha,scale=beta)
p_x
##  Simulation of mean and variance   Estimates!!
x=rgamma(1000000,alpha,scale=beta)
mean(x)
##  Develop the Gamma density and provide probabilities within limits
##
xmin=0
xmax=0.14
alpha=1
beta=(1/3)
cc <- curve(dgamma(x,alpha,scale=beta), from = 0, to = max(alpha*beta*4), main="Gamma density at various levels of x",xlab = "x", ylab = "p(x)")
polygon(c(xmin, cc$x[cc$x >= xmin & cc$x <= xmax], xmax), c(0, cc$y[cc$x >= xmin & cc$x <= xmax], 0), col = "red")
p_x=pgamma(xmax,alpha,scale=beta)-pgamma(xmin,alpha,scale=beta)
p_x
##  Develop the Gamma density and provide probabilities within limits
##
xmin=1.33
xmax=2
alpha=8
beta=(1/3)
cc <- curve(dgamma(x,alpha,scale=beta), from = 0, to = max(alpha*beta*4), main="Gamma density at various levels of x",xlab = "x", ylab = "p(x)")
polygon(c(xmin, cc$x[cc$x >= xmin & cc$x <= xmax], xmax), c(0, cc$y[cc$x >= xmin & cc$x <= xmax], 0), col = "red")
p_x=pgamma(xmax,alpha,scale=beta)-pgamma(xmin,alpha,scale=beta)
p_x
# Fetch taxonomic information for the species
tax_info <- classification(tax_ids)
library(taxize)
library(ape)
# Define the species of interest
species_names <- c("Homo sapiens", "Pan troglodytes", "Canis lupus", "Felis catus", "Mus musculus")
# Retrieve taxonomic IDs for the species
tax_ids <- get_ids(species_names, db = "ncbi")
library(taxize)
library(ape)
# Define the species of interest
species_names <- c("Homo sapiens", "Pan troglodytes", "Canis lupus", "Felis catus", "Mus musculus")
# Retrieve taxonomic IDs for the species
tax_ids <- get_ids(species_names, db = "ncbi")
# Fetch taxonomic information for the species
tax_info <- classification(tax_ids)
# Construct a phylogenetic tree
tree <- tax2phylo(tax_info)
# Extract the taxonomic lineage for each species
lineages <- lapply(tax_info$`Taxonomic lineage`, function(x) rev(unlist(strsplit(x, "; "))))
# Create a matrix with the species as rows and taxonomic levels as columns
tax_matrix <- t(sapply(lineages, function(x) {
result <- rep(NA, length(levels(factor(unlist(lineages)))))
result[1:length(x)] <- x
return(result)
}))
# Convert the matrix to a phylo object
tree <- tax2phylo(tax_matrix, keep.all = TRUE)
# Create a list to store taxonomic lineage for each species
lineages <- lapply(tax_info, function(x) strsplit(x$classification, ";")[[1]])
# Find the common ancestor
common_ancestor <- Reduce(intersect, lineages)
# Find the index of the common ancestor
ancestor_index <- which(lineages[[1]] == common_ancestor)
# Create a matrix to represent the tree
tree_matrix <- sapply(lineages, function(x) {
rep(NA, length(common_ancestor) + 1)
})
# Fill the matrix with taxonomic levels
for (i in 1:length(lineages)) {
tree_matrix[i, 1:length(lineages[[i]])] <- lineages[[i]]
}
# Convert the matrix to a phylo object
tree <- as.phylo(tree_matrix)
# Plot the tree
plot(tree)
?as.phylo()
library(taxize)
library(ape)
# Define the species of interest
species_names <- c("Homo sapiens", "Pan troglodytes", "Canis lupus", "Felis catus", "Mus musculus")
# Retrieve taxonomic IDs for the species
tax_ids <- get_ids(species_names, db = "ncbi")
out <- classification(spnames, db='itis')
out <- classification(tax_ids, db='ncbi')
tr <- class2tree(out)
# Define the species of interest
species_names <- c("Homo sapiens", "Pan troglodytes", "Canis lupus", "Felis catus", "Mus musculus")
out <- classification(species_names, db='ncbi')
tr <- class2tree(out)
plot(tr)
# Define the species of interest
species_names <- c("Homo sapiens", "Pan troglodytes", "Canis lupus", "Felis catus", "Mus musculus,
Rattus norvegicus, Pan paniscus, Danio rerio, Meleagris gallopavo,
Anolis carolinensis, Sus scrofa, Gorilla gorilla, Petromyzon marinus")
out <- classification(species_names, db='ncbi')
# Define the species of interest
species_names <- c("Homo sapiens", "Pan troglodytes", "Canis lupus", "Felis catus", "Mus musculus,
Rattus norvegicus, Pan paniscus, Danio rerio, Meleagris gallopavo,
Anolis carolinensis, Sus scrofa, Gorilla gorilla, Petromyzon marinus")
out <- classification(species_names, db='ncbi')
# Define the species of interest
species_names <- c("Homo sapiens", "Pan troglodytes", "Canis lupus", "Felis catus", "Mus musculus",
"Rattus norvegicus", "Pan paniscus", "Danio rerio", "Meleagris gallopavo",
"Anolis carolinensis", "Sus scrofa", "Gorilla gorilla", "Petromyzon marinus")
out <- classification(species_names, db='ncbi')
tr <- class2tree(out)
plot(tr)
?plot()
View(tr)
plot(tr)
setwd("C:/Users/danie/OneDrive - Texas A&M University/Wanhe_Li/Esther_Code/July/Prototype")
shiny::runApp(getwd())
shiny::runApp(getwd())
shiny::runApp(getwd())
?actionButton
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
Sys.setenv(SHINY_MAX_REQUEST_SIZE = 100 * 1024^2)  # 100 MB
runApp()
runApp()
runApp()
?observe()
